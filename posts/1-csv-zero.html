<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<script type="application/ld+json">
      {
        "@context": "https://schema.org",
        "@type": "WebSite",
        "name": "Peyman Mortazavi - Seasoned Software Engineer",
        "url": "https://peymanmo.com/"
      }
    </script>
	
		<link href="../_app/immutable/assets/0.rerjPoCJ.css" rel="stylesheet">
		<link href="../_app/immutable/assets/5.DciVjBd_.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.B786fUBl.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DO7qxSPC.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/kim3C5FY.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DC1HeBj6.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/om88xCLe.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DpiXYlSK.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.DwzasE_N.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/lWdWeu1k.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DsnmJJEf.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/S_Wn93zL.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/CjPrM--i.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/C7Kzoay9.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.D3g-8nUm.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Ce_L8zom.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/0L3d-nfU.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/5.C1zeZ8jT.js"><!--[--><link rel="icon" href="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='107'%20height='128'%20viewBox='0%200%20107%20128'%3e%3ctitle%3esvelte-logo%3c/title%3e%3cpath%20d='M94.157%2022.819c-10.4-14.885-30.94-19.297-45.792-9.835L22.282%2029.608A29.92%2029.92%200%200%200%208.764%2049.65a31.5%2031.5%200%200%200%203.108%2020.231%2030%2030%200%200%200-4.477%2011.183%2031.9%2031.9%200%200%200%205.448%2024.116c10.402%2014.887%2030.942%2019.297%2045.791%209.835l26.083-16.624A29.92%2029.92%200%200%200%2098.235%2078.35a31.53%2031.53%200%200%200-3.105-20.232%2030%2030%200%200%200%204.474-11.182%2031.88%2031.88%200%200%200-5.447-24.116'%20style='fill:%23ff3e00'/%3e%3cpath%20d='M45.817%20106.582a20.72%2020.72%200%200%201-22.237-8.243%2019.17%2019.17%200%200%201-3.277-14.503%2018%2018%200%200%201%20.624-2.435l.49-1.498%201.337.981a33.6%2033.6%200%200%200%2010.203%205.098l.97.294-.09.968a5.85%205.85%200%200%200%201.052%203.878%206.24%206.24%200%200%200%206.695%202.485%205.8%205.8%200%200%200%201.603-.704L69.27%2076.28a5.43%205.43%200%200%200%202.45-3.631%205.8%205.8%200%200%200-.987-4.371%206.24%206.24%200%200%200-6.698-2.487%205.7%205.7%200%200%200-1.6.704l-9.953%206.345a19%2019%200%200%201-5.296%202.326%2020.72%2020.72%200%200%201-22.237-8.243%2019.17%2019.17%200%200%201-3.277-14.502%2017.99%2017.99%200%200%201%208.13-12.052l26.081-16.623a19%2019%200%200%201%205.3-2.329%2020.72%2020.72%200%200%201%2022.237%208.243%2019.17%2019.17%200%200%201%203.277%2014.503%2018%2018%200%200%201-.624%202.435l-.49%201.498-1.337-.98a33.6%2033.6%200%200%200-10.203-5.1l-.97-.294.09-.968a5.86%205.86%200%200%200-1.052-3.878%206.24%206.24%200%200%200-6.696-2.485%205.8%205.8%200%200%200-1.602.704L37.73%2051.72a5.42%205.42%200%200%200-2.449%203.63%205.79%205.79%200%200%200%20.986%204.372%206.24%206.24%200%200%200%206.698%202.486%205.8%205.8%200%200%200%201.602-.704l9.952-6.342a19%2019%200%200%201%205.295-2.328%2020.72%2020.72%200%200%201%2022.237%208.242%2019.17%2019.17%200%200%201%203.277%2014.503%2018%2018%200%200%201-8.13%2012.053l-26.081%2016.622a19%2019%200%200%201-5.3%202.328'%20style='fill:%23fff'/%3e%3c/svg%3e"/><!--]--><!--[--><meta name="description" content="Journey into designing a fast CSV iterator using SIMD and avoiding dynamic memory allocations"/><!--]--><title>Zero-allocation, SIMD accelerated CSV iterator</title>
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents"><!--[--><!--[--><!----><div class="bg-background-200 w-screen h-screen relative overflow-hidden"><!--[!--><!--]--><!----> <div class="absolute inset-0 flex flex-col"><div class="flex flex-row h-16 flex-shrink-0"><div class="gap svelte-10dujo8"></div> <div class="flex flex-row h-full flex-1 items-center justify-around md:justify-start mx-4 gap-6"><a href="/" class="text-2xl">info</a> <a href="/resume" class="text-2xl">resume</a> <a href="/opensource" class="text-2xl">open source</a> <a href="/posts" class="text-2xl">posts</a></div> <div class="gap svelte-10dujo8"></div></div> <div class="flex flex-row flex-1 overflow-hidden"><div class="gap svelte-10dujo8"></div> <div class="flex-1 overflow-hidden"><div class="flex flex-col relative h-full overflow-x-hidden z-20 flex-1 overflow-scroll"><!----><div class="p-2 pr-4 md:p-4 lg:p-6 xl:p-12 font-mono"><span class="text-xl md:text-2xl lg:text-3xl xl:text-4xl font-bold">Zero-allocation, SIMD accelerated CSV iterator</span> <br/> <div class="flex md:items-center justify-between flex-col md:flex-row"><span class="text-lg lg:text-xl xl:text-2xl">Journey into designing a fast CSV iterator using SIMD and avoiding dynamic memory allocations</span> <span class="xl:text-xl">February 9, 2026</span></div></div> <div id="post-container" class="p-2 pt-6 md:p-4 lg:p-6 xl:p-12 md:pt-0 md:text-justify xl:text-xl font-[Dosis]"><!----><h1>Introduction</h1> <p>CSV parsing is one of those problems that looks trivial until you try to do it <em>well</em>. The format itself is simple, but supporting quoted fields, escape sequences, and multiple line-ending conventions—while still delivering high throughput—requires careful design.</p> <p>In this post, I’ll walk through the design of <strong>csv-zero</strong>, a SIMD-accelerated, zero-allocation CSV iterator. We’ll explore the techniques used to achieve high performance, the tradeoffs involved, and the constraints that shaped the final architecture.</p> <p>Specifically, we’ll cover:</p> <ul><li>Why iterating <em>fields</em> instead of <em>records</em> enables zero allocation</li> <li>How SIMD can be used to efficiently locate CSV delimiters</li> <li>How branch reduction improves performance in hot loops</li> <li>How quoted fields are handled</li> <li>The benchmarking methodology used to evaluate these choices</li></ul> <p>If you’re interested in SIMD programming, branch prediction, or systems-level optimization, you may find some reusable patterns here.</p> <p>The implementation is written in <strong>Zig</strong>, so examples reference Zig syntax and semantics, but the underlying ideas are largely language-agnostic and applicable to C, C++, Rust, or similar systems languages.</p> <h2>A brief introduction to the CSV format</h2> <p>If you are already familiar with CSV, feel free to skip this section.</p> <p>CSV does have an RFC specification—<a href="https://www.rfc-editor.org/rfc/rfc4180" rel="nofollow">RFC 4180</a>—which is concise and readable. Below is a distilled version of the rules relevant to this discussion.</p> <p>At a high level:</p> <ul><li>A CSV file is a sequence of <strong>records</strong></li> <li>Each record appears on its own line</li> <li>Each record consists of one or more <strong>fields</strong>, separated by commas</li></ul> <h3>Fields</h3> <p>A field may be either:</p> <ol><li><strong>Unquoted</strong>, containing any characters except commas, quotes, or line breaks</li> <li><strong>Quoted</strong>, enclosed in double quotes (<code>"</code>)</li></ol> <p>Quoted fields may contain:</p> <ul><li>Commas</li> <li>Line breaks</li> <li>Escaped quotes, represented as two consecutive double quotes (<code>""</code>)</li></ul> <p>Examples:</p> <pre class="language-undefined"><!----><code class="language-undefined">a,b,c
&quot;hello, world&quot;,42,&quot;foo&quot;&quot;bar&quot;</code><!----></pre> <h3>Line endings</h3> <p>Records may be terminated by:</p> <ul><li>LF (<code>\n</code>)</li> <li>CRLF (<code>\r\n</code>)</li></ul> <p>A correct parser must handle both.</p> <p>Understanding these rules is critical for parser implementation because each rule introduces branching logic and state management that impacts performance.</p> <h1>Implementation overview</h1> <p>The primary goal of csv-zero is <strong>performance</strong>, with the explicit constraint of <strong>zero dynamic allocation</strong> in the iterator. To achieve this, the implementation focuses on three main design choices:</p> <ol><li>Iterating over <strong>fields</strong>, not records</li> <li>Using <strong>SIMD</strong> to locate delimiters</li> <li>Reducing <strong>branches</strong> in hot paths</li></ol> <p>The core abstraction is an iterator with a <code>next()</code> method that returns the next field or an error.</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token keyword">const</span> <span class="token class-name">Field</span> <span class="token operator">=</span> <span class="token keyword">struct</span> <span class="token punctuation">&#123;</span>
    data<span class="token punctuation">:</span> <span class="token class-name"><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin-type keyword">u8</span></span><span class="token punctuation">,</span>
    last_column<span class="token punctuation">:</span> <span class="token class-name"><span class="token builtin-type keyword">bool</span></span><span class="token punctuation">,</span>
    needs_unescape<span class="token punctuation">:</span> <span class="token class-name"><span class="token builtin-type keyword">bool</span></span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> IteratorError <span class="token operator">=</span> <span class="token keyword">error</span><span class="token punctuation">&#123;</span> EOF<span class="token punctuation">,</span> FieldTooLong <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> <span class="token class-name">Iterator</span> <span class="token operator">=</span> <span class="token keyword">struct</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">pub</span> <span class="token keyword">fn</span> <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token class-name">IteratorError<span class="token operator">!</span>Field</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// ...</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">;</span></code><!----></pre> <p>The production implementation includes additional error types and field metadata, but this simplified interface captures the essential contract.</p> <p>Conceptually, the iterator works as follows:</p> <ol><li><p>Scan the buffer for the next delimiter (comma, newline, or quote)</p></li> <li><p>If the delimiter is a comma or newline:</p> <ul><li>Return the field up to that point</li></ul></li> <li><p>If the delimiter is a quote:</p> <ul><li><p>Enter quoted-field handling logic:</p> <ul><li>Search for the matching closing quote</li> <li>Handle escaped quotes (<code>""</code>)</li> <li>Validate the character following the closing quote</li> <li>Return the quoted field or an error</li></ul></li></ul></li></ol> <p>In pseudocode:</p> <pre class="language-undefined"><!----><code class="language-undefined">function next():
    find next delimiter (quote, comma, newline)

    if delimiter is comma or newline:
        return field

    if delimiter is quote:
        loop:
            find next quote
            if escaped quote:
                skip
            else if followed by comma or newline:
                return field
            else if end of input:
                return field
            else:
                error</code><!----></pre> <p>While the algorithm appears straightforward, correct implementation requires careful handling of buffer boundaries, escape sequences, and line ending variations. The following sections detail how SIMD, zero-allocation, and branch reduction address these challenges.</p> <h2>Zero Allocation</h2> <p>Dynamic memory allocation introduces overhead that compounds at scale. Even with efficient allocators, allocations involve:</p> <ul><li>Allocator bookkeeping and metadata updates</li> <li>Potential cache pollution from accessing allocator data structures</li> <li>Memory fragmentation over time</li> <li>Unpredictable latency, especially with general-purpose allocators like <code>malloc</code>/<code>free</code></li></ul> <p>While arena allocators and custom allocation strategies can mitigate some of these costs, eliminating allocations entirely is more efficient. This is why csv-zero is architected to operate entirely on a fixed-size buffer without any dynamic allocations during parsing.</p> <p>To completely avoid dynamic allocation, csv-zero deliberately iterates over <strong>fields</strong>, not <strong>records</strong>.</p> <p>Instead of returning an array of fields for each record, the iterator returns one field at a time as a slice into an internal buffer. That slice is valid only until the next call to <code>next()</code>, at which point the buffer may be reused or refilled.</p> <p>This design choice has consequences.</p> <h3>Why not record iteration?</h3> <p>Many CSV libraries expose a record-oriented API:</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token keyword">while</span> <span class="token punctuation">(</span>iterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">|</span>record<span class="token operator">|</span> <span class="token punctuation">&#123;</span>
    total <span class="token operator">+=</span> <span class="token function">parseInt</span><span class="token punctuation">(</span>record<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span></code><!----></pre> <p>This is convenient, but fundamentally incompatible with zero allocation:</p> <ul><li>The number of fields per record is not known at compile time</li> <li>Returning a record requires storing all field slices somewhere</li> <li>That storage must either be dynamically allocated or capped at an arbitrary maximum</li></ul> <p>You <em>can</em> mitigate this by reusing allocations, but at that point the design is no longer truly allocation-free. You still have to buffer the entire record, which places a significant constraint on the iterator and, in practice, often pushes users back toward explicit memory allocation anyway.</p> <p>By iterating over fields instead, csv-zero avoids all of these issues. Users who want record-level iteration can easily build it on top of the field iterator, while users focused on streaming transformations—filtering, validation, conversion—avoid unnecessary buffering entirely.</p> <p>In many practical workloads (e.g. CSV → JSON conversion, column selection, data cleanup), record materialization provides little benefit.</p> <h2>Buffer sliding and oversized fields</h2> <p>Because fields are returned as slices into a fixed buffer, the buffer must be large enough to hold the largest field encountered. If a field exceeds the buffer size, the iterator returns a <code>FieldTooLong</code> error, allowing the caller to decide how to proceed (allocate dynamically, skip the field, abort, etc.).</p> <p>The key challenge is maximizing buffer utilization. If a field starts in the middle of the buffer and extends beyond the current buffered data, we need to:</p> <ol><li><strong>Slide</strong> the partial field to the beginning of the buffer using <code>@memmove</code></li> <li><strong>Fill</strong> the remaining buffer space by reading more data from the input stream</li> <li><strong>Resume</strong> scanning from where we left off</li></ol> <p>This sliding window technique ensures that any field smaller than the buffer size can be parsed, regardless of its alignment within the input stream.</p> <p><img src="/p/1-csv-zero-buffer-sliding.svg" alt="Buffer sliding and refilling"/></p> <h2>SIMD-accelerated delimiter scanning</h2> <p>SIMD (<em>Single Instruction, Multiple Data</em>) allows a single CPU instruction to operate on multiple data elements simultaneously.
This data-level parallelism is ideal for operations like searching for delimiters, where we need to compare many bytes against the same set of characters.
Modern CPUs support wide vector registers (128–512 bits, 16-64 bytes).</p> <p>If you’re unfamiliar with SIMD, I recommend reading about <a href="https://zig.guide/language-basics/vectors/" rel="nofollow">Zig Vectors</a> or reviewing your architecture’s SIMD instruction set documentation.</p> <p>In csv-zero, SIMD is used to locate delimiter characters—quotes (<code>"</code>), commas (<code>,</code>), and newlines (<code>\n</code>)—by processing multiple bytes at once.</p> <p>Using Zig vectors:</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token keyword">const</span> Vector <span class="token operator">=</span> <span class="token builtin">@Vector</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token builtin-type keyword">u8</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> input<span class="token punctuation">:</span> <span class="token class-name">Vector</span> <span class="token operator">=</span> buffer<span class="token punctuation">[</span>cursor<span class="token operator">..</span>cursor<span class="token operator">+</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token operator">.*</span><span class="token punctuation">;</span> <span class="token comment">// Load 16 bytes from buffer.</span>

<span class="token keyword">const</span> quotes   <span class="token operator">=</span> input <span class="token operator">==</span> <span class="token builtin">@splat</span><span class="token punctuation">(</span><span class="token char">'"'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> commas   <span class="token operator">=</span> input <span class="token operator">==</span> <span class="token builtin">@splat</span><span class="token punctuation">(</span><span class="token char">','</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> newlines <span class="token operator">=</span> input <span class="token operator">==</span> <span class="token builtin">@splat</span><span class="token punctuation">(</span><span class="token char">'&#92;n'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> delimiters <span class="token operator">=</span> <span class="token punctuation">(</span>quotes <span class="token operator">|</span> commas <span class="token operator">|</span> newlines<span class="token punctuation">)</span><span class="token punctuation">;</span></code><!----></pre> <p>This produces a vector of booleans indicating the positions of delimiter characters.
The entire operation executes in just a few SIMD instructions, processing 16+ bytes in parallel.</p> <p>Note that <code>@splat</code> in Zig creates an array or vector where each element is set to the same scalar value.</p> <p>For illustration purposes in this article, we’ll use 6-byte vectors to keep diagrams readable. In production, csv-zero automatically selects the optimal vector length for the target architecture at compile time.</p> <p><img src="/p/1-csv-zero-simd.svg" alt="Delimiter vector compution using SIMD"/></p> <p><strong>NOTE</strong>: The actual bit representation of <code>delimiters</code> uses little-endian bit ordering (LSB = index 0). The diagram shows a human-friendly left-to-right ordering for readability, but the implementation must account for the actual CPU representation when extracting bit positions.</p> <p>To efficiently consume this result, the boolean vector is bit-cast to an integer:</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token keyword">const</span> Bitmask <span class="token operator">=</span> std<span class="token punctuation">.</span>meta<span class="token punctuation">.</span><span class="token function">Int</span><span class="token punctuation">(</span><span class="token punctuation">.</span>unsigned<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> mask<span class="token punctuation">:</span> <span class="token class-name">Bitmask</span> <span class="token operator">=</span> <span class="token builtin">@bitCast</span><span class="token punctuation">(</span>delimiters<span class="token punctuation">)</span><span class="token punctuation">;</span></code><!----></pre> <p>This enables fast integer operations instead of higher-level SIMD helpers.</p> <h3>Why integers instead of SIMD helpers?</h3> <p>In practice, treating the mask as an integer and using bit-twiddling operations (<code>@ctz</code>, <code>&amp;=</code>) proved significantly faster than calling helper functions like <code>std.simd.firstTrue</code>.</p> <p>Additionally, from now on, most of the operations, as you will see, are simple integer operations.</p> <h2>Finding and consuming delimiters</h2> <p>Once the delimiter mask is available:</p> <ul><li>If <code>mask == 0</code>, there are no delimiters in this chunk</li> <li>Otherwise, find the index of the next delimiter in <code>mask</code></li></ul> <p>To find the position of the next delimiter, we need to locate the least significant set bit (the rightmost <code>1</code>) in our bitmask. This is done efficiently using the <strong>count trailing zeros</strong> (CTZ) instruction:</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token keyword">const</span> index <span class="token operator">=</span> <span class="token builtin">@ctz</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">;</span></code><!----></pre> <p>The CTZ instruction counts the number of consecutive zero bits starting from the LSB, which directly gives us the bit index. On x86-64, this compiles to a single <code>TZCNT</code> or <code>BSF</code> instruction.</p> <p>To avoid returning the same delimiter again, the least significant set bit is cleared:</p> <pre class="language-zig"><!----><code class="language-zig">mask <span class="token operator">&amp;=</span> mask <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span></code><!----></pre> <p>This classic trick compiles down to a single instruction on many architectures (e.g. <code>BLSR</code>).</p> <p><strong>Why this works</strong>: Subtracting 1 from a number flips all trailing zeros to ones and flips the rightmost <code>1</code> to <code>0</code>. The bitwise AND then clears everything up to and including that bit:</p> <pre class="language-undefined"><!----><code class="language-undefined">A     : 0b110100  (original)
A - 1 : 0b110011  (rightmost 1 becomes 0, trailing 0s become 1s)
&amp;     : 0b110000  (AND clears the rightmost 1 and all trailing bits)</code><!----></pre> <p>This gives us a two-instruction loop for iterating through set bits: CTZ to find the position, then clear the bit. Effectively using the <code>mask</code> integer variable as a queue. This is significantly faster than scalar iteration or branching based on individual bit tests.</p> <h2>Integrating SIMD into the iterator</h2> <p>A helper like <code>nextDelim()</code> encapsulates this logic:</p> <ul><li><p>If a cached delimiter mask exists, pop from it</p></li> <li><p>Otherwise:</p> <ul><li>Load the next SIMD chunk</li> <li>Compute the delimiter mask</li> <li>Cache it and return the first delimiter</li></ul></li> <li><p>Fall back to byte-by-byte scanning near buffer boundaries</p></li></ul> <p>The main <code>next()</code> function repeatedly calls <code>nextDelim()</code> until it can return a field, refill the buffer, or signal EOF or error.</p> <p><img src="/p/1-csv-zero-vector-pop.svg" alt="Pop least significant set bit"/></p> <h2>Handling quoted fields</h2> <p>Quoted fields introduce complexity and branching. To keep the fast path fast, csv-zero separates quoted and unquoted logic early:</p> <ul><li>If the next delimiter is <strong>not</strong> a quote, it is treated as a field boundary</li> <li>If it <strong>is</strong> a quote, a dedicated quoted-field routine is entered</li></ul> <p>Key goals when handling quoted fields:</p> <ol><li><p><strong>Detect escaped quotes</strong> Escaped quotes (<code>""</code>) are detected but not immediately unescaped. Instead, the returned <code>Field</code> includes a <code>needs_unescape</code> flag, allowing the caller to decide whether to pay the cost.</p></li> <li><p><strong>Locate the closing quote and trailing delimiter</strong> The parser must consume:</p> <ul><li>The opening quote</li> <li>Any escaped quotes</li> <li>The closing quote</li> <li>The following comma or newline (if present)</li></ul></li></ol> <p>This logic is implemented as a small finite-state automaton, consuming delimiters until the quoted region is complete.</p> <p><img src="/p/1-csv-zero-fsa-quotes.svg" alt="FSA for handling quoted regions"/></p> <h2>Reducing branches in hot loops</h2> <p>Modern CPUs rely on branch prediction to maintain instruction pipeline efficiency. When a branch is mispredicted, the pipeline must be flushed, incurring a substantial cycle penalty. In tight loops processing millions of fields, even infrequent mispredictions compound into measurable overhead.</p> <p>At this level of optimization, branch misprediction becomes a real cost.</p> <p>One notable example is handling both LF and CRLF line endings. Rather than branching on <code>\r</code>, the parser only checks for <code>\n</code>. If the delimiter is <code>\n</code>, a branch-free computation determines whether the preceding byte was <code>\r</code> and trims it if necessary:</p> <pre class="language-zig"><!----><code class="language-zig"><span class="token comment">// Branching version (susceptible to misprediction)</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>delim <span class="token operator">==</span> <span class="token char">'&#92;n'</span> <span class="token keyword">and</span> end <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">and</span> buffer<span class="token punctuation">[</span>end <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token char">'&#92;r'</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> buffer<span class="token punctuation">[</span>start <span class="token operator">..</span> end <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">// Trim &#92;r</span>
<span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> buffer<span class="token punctuation">[</span>start <span class="token operator">..</span> end<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token comment">// Branch-free version</span>
<span class="token keyword">const</span> prev_is_cr <span class="token operator">=</span> <span class="token builtin">@intFromBool</span><span class="token punctuation">(</span>end <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">and</span> buffer<span class="token punctuation">[</span>end <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token char">'&#92;r'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> is_newline <span class="token operator">=</span> <span class="token builtin">@intFromBool</span><span class="token punctuation">(</span>delim <span class="token operator">==</span> <span class="token char">'&#92;n'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> trim_cr <span class="token operator">=</span> prev_is_cr <span class="token operator">&amp;</span> is_newline<span class="token punctuation">;</span>  <span class="token comment">// 1 if we need to trim &#92;r, 0 otherwise</span>

<span class="token keyword">return</span> buffer<span class="token punctuation">[</span>start <span class="token operator">..</span> end <span class="token operator">-</span> trim_cr<span class="token punctuation">]</span><span class="token punctuation">;</span></code><!----></pre> <p>This avoids conditional jumps entirely, reducing misprediction in a hot path.</p> <p>Similar techniques are used elsewhere, but this change alone produced measurable improvements.</p> <h1>Benchmarking</h1> <p>Rigorous benchmarking is critical for validating optimization claims. I created <a href="https://github.com/peymanmortazavi/csv-race" rel="nofollow">csv-race</a>, a benchmarking harness that compares multiple CSV parsers using Linux <code>perf</code> and other profiling tools. The repository provides reproducible methodology for generating performance metrics:</p> <ul><li><strong>Wall-clock latency</strong>: Total time to process the file</li> <li><strong>Branch miss rate</strong>: Percentage of branch mispredictions</li> <li><strong>Cache locality</strong>: Cache miss statistics</li> <li><strong>Peak RSS</strong>: Maximum resident set size (memory usage)</li></ul> <p><strong>Methodology</strong>: To isolate parser performance from downstream processing, the benchmark measures only iteration throughput—no numerical conversion, string manipulation, or data structure building. The task is simply to iterate every field and count them. All parsers use a fixed 64KB buffer to ensure fair comparison.</p> <p><strong>Test corpus</strong>: The benchmark suite includes commonly-used CSV files (WorldCities, NFL games) plus synthetically generated files with controlled characteristics:</p> <ul><li>Varying record counts (different file sizes)</li> <li>Varying field lengths</li> <li>Varying column counts</li> <li>Files with and without quoted fields</li></ul> <p>This diversity ensures the benchmarks reflect real-world CSV file heterogeneity rather than overfitting to a single pattern.</p> <p>Here’s the results from the benchmarks:</p> <h3>Latency (small files)</h3> <p><img src="https://github.com/peymanmortazavi/csv-race/raw/main/images/wall_time.png" alt="Time Latency - Small Files"/></p> <h3>Latency (large files)</h3> <p><img src="https://github.com/peymanmortazavi/csv-race/raw/main/images/wall_time_xl.png" alt="Time Latency - Large Files"/></p> <h3>Branch misses</h3> <p><img src="https://github.com/peymanmortazavi/csv-race/raw/main/images/branch_misses.png" alt="Branch Misses"/></p> <h1>Conclusion</h1> <p>Designing a fast CSV parser turned out to be a far richer problem than it initially appeared. By committing to zero allocation, leveraging SIMD for delimiter detection, and aggressively reducing branches, csv-zero achieves high throughput while remaining simple and predictable.</p> <p>The implementation is available at <a href="https://github.com/peymanmortazavi/csv-zero" rel="nofollow">github.com/peymanmortazavi/csv-zero</a> and is ready to use. I have plans to add additional utilities, but the core library is production-ready. A C-compatible interface is included for integration with C/C++ projects.</p> <p>I want to express my enthusiasm for the Zig language. Zig has made exploring low-level concepts—custom allocators, SIMD via @Vector, explicit memory control, and compile-time code generation—both accessible and enjoyable. There are many factors to consider when choosing a programming language, but for me, Zig is by far the most enjoyable language to work in—and that enjoyment is not limited to low-level programming.</p> <p>I want to thank everyone involved in the Zig language and its community. I already support the Zig Software Foundation and encourage you to explore the language, contribute bug reports, share your experiences, or support it financially if it resonates with you.</p><!----></div><!----><!----></div></div> <div class="right-gap svelte-10dujo8"></div></div> <div class="flex flex-row h-0 md:h-16 flex-shrink-0"><div class="gap svelte-10dujo8"></div></div></div></div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_1dppi4e = {
						base: new URL("..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("../_app/immutable/entry/start.B786fUBl.js"),
						import("../_app/immutable/entry/app.DwzasE_N.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data: [null,null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>
